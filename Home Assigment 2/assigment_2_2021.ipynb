{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skoltech\n",
    "## Intro to data science, fall 2021\n",
    "## Assigment 2\n",
    "\n",
    "### Goals\n",
    "- Make exploratory data analysis\n",
    "- Apply feature engineering and feature selection\n",
    "- Try to solve classification tasks and use classification performance metrics\n",
    "\n",
    "\n",
    "# Submiting the answers\n",
    "\n",
    "Google form to submit your answers: https://docs.google.com/forms/d/e/1FAIpQLSfAQzhQGmdCYLtaeeaAn2mgNut5HO4U6l3G1KUbBO0qDtA7FA/viewform\n",
    "\n",
    "Use your **skoltech email**. For Name, Surname use **exactly the same spelling** as in canvas system.\n",
    "\n",
    "---\n",
    "\n",
    "If your answer is a ``float number``, then you must round it up to **3 decimals after the floating point**, e.g. 3.142 for pi or 9.78 for 9.780023\n",
    "\n",
    "---\n",
    "\n",
    "If your answer is a ``list of float or integer numbers``, then they should be reported in descending order, divided by a comma, e.g.:\n",
    "\n",
    "10.453,9.112,5.001,5.000,1.02\n",
    "\n",
    "If your answer is a ``list of str or letters``, then they should be in alphabetical order , e.g.:\n",
    "\n",
    "charlie,foxtrot,kilo,uniform\n",
    "\n",
    "a,c,f\n",
    "\n",
    "---\n",
    "\n",
    "The last part (Q5) does not have corresponding fields in the google form. It is **not optional** and it will be graded manually from your .ipynb file.\n",
    "\n",
    "---\n",
    "\n",
    "If you have any questions regarding this Home Assignment, you can ask them on piazza:https://piazza.com/class/ku068l4dg0068n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Customer Personality Analysis is a detailed analysis of a company’s ideal customers. It helps a business to better understand its customers and makes it easier for them to modify products according to the specific needs, behaviors and concerns of different types of customers.\n",
    "\n",
    "#### Attributes\n",
    "\n",
    "**People**\n",
    "\n",
    "-   ID: Customer's unique identifier\n",
    "-   Year_Birth: Customer's birth year\n",
    "-   Education: Customer's education level\n",
    "-   Marital_Status: Customer's marital status\n",
    "-   Kidhome: Number of children in customer's household\n",
    "-   Teenhome: Number of teenagers in customer's household\n",
    "-   Dt_Customer: Date of customer's enrollment with the company\n",
    "-   Recency: Number of days since customer's last purchase\n",
    "-   Complain: 1 if customer complained in the last 2 years, 0 otherwise\n",
    "\n",
    "\n",
    "**Products**\n",
    "\n",
    "-   MntWines: Amount spent on wine in last 2 years\n",
    "-   MntFruits: Amount spent on fruits in last 2 years\n",
    "-   MntMeatProducts: Amount spent on meat in last 2 years\n",
    "-   MntFishProducts: Amount spent on fish in last 2 years\n",
    "-   MntSweetProducts: Amount spent on sweets in last 2 years\n",
    "-   MntGoldProds: Amount spent on gold in last 2 years\n",
    "\n",
    "**Promotion**\n",
    "\n",
    "-   NumDealsPurchases: Number of purchases made with a discount\n",
    "-   AcceptedCmp: 1 if customer accepted the offer in the last campaign, 0 otherwise\n",
    "\n",
    "**Behavior**\n",
    "\n",
    "-   NumWebPurchases: Number of purchases made through the company’s web site\n",
    "-   NumCatalogPurchases: Number of purchases made using a catalogue\n",
    "-   NumStorePurchases: Number of purchases made directly in stores\n",
    "-   NumWebVisitsMonth: Number of visits to company’s web site in the last month\n",
    "-   NumDealsPurchases: Number of purchases made with a discount\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Import basic libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IxQ5oO5xbtyW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mBWPB2ajcTnj"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('marketing_campaign.csv', sep='\\t', index_col='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Data exploration\n",
    "\n",
    "Let's take a closer look at the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.1\n",
    "\n",
    "#### How many columns in the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.2\n",
    "\n",
    "#### How many unique marital statuses are there?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Q1.3\n",
    "#### What is the average age, if we assume now it is 2021? E.g. if we would have two people born in 2001 and 1999, the average age would be 21. Please answer with an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.4\n",
    "#### There are some columns related to spendings by category, they are starting with 'Mnt': MntWines, MntFruits, etc. In which category people spent the most on average?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.5\n",
    "\n",
    "There are columns describing how customers make their orders, these columns start with num, e.g. 'NumDealsPurchases',\n",
    " or 'NumWebPurchases'. Build a histogram for the number of web visits (NumWebVisitsMonth). What is the 'most popular' number of visits, i.e. what number of visits encounters most often in the column?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.6 \n",
    "\n",
    "Let's try to analyze different features together. Build a [pairplot](https://seaborn.pydata.org/generated/seaborn.pairplot.html) for all the 'Num..' columns with 'AcceptedCmp' as a 'hue' argument. The hue argument adds a color marker to the plots and it will allow us to analyze how customers with different behavior patterns react to the marketing proposals. Note, to use the column as hue, it should be passed with the rest of the columns; also you can pass `kind='scatter', plot_kws=dict(alpha=0.2)` arguments to make the dots semi-transparent.\n",
    "\n",
    "Which of the statements are true, if judged from the plot?\n",
    "- (a) The people, who don't visit web site don't buy with a discount\n",
    "- (b) All the people who often visit the website buy a lot online\n",
    "- (c) People, who buy with a discount, much more often accept marketing campaign\n",
    "- (d) There is not any clear dependency between web visits and the number of catalog purchases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.7\n",
    "\n",
    "Build a [crosstab](https://pandas.pydata.org/docs/reference/api/pandas.crosstab.html) for teen at home ('Teenhome') and kids at home ('Kidhome'). How many customers have 2 kids and a single teenager?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.8\n",
    "There is a 'Dt_Customer' column with a customer registration date. In which month there were a maximum number of registrations? Answer with the name, i.e. 'January'. Hint: you probably want to convert the column to datetime from string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing\n",
    "The goal of the segment is to prepare data for further work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.1\n",
    "There are two columns, that has the same value for all the people and they don't have a description in the sections above. Let's drop them. As an answer, write the names of these columns divided by a comma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.2\n",
    "As we could see before, there are some strange rare marital statuses. We going to leave only three options - 'Married', 'Together' and 'Single'. All other options should be changed to 'Single'. How many people are now in this category?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.3\n",
    "\n",
    "Now it's time to talk about the task for today. Our big retail company \"Y6\" want to launch a marketing campaign, but we want to make the marketing proposal only to people, who would accept it with the high probability. So we need to build a model that would predict it.\n",
    "\n",
    "Let's divide the dataset into a target (the 'AcceptedCmp' column) and data (the rest of the columns). How many positive labels are there in target?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2.4\n",
    "\n",
    "To honestly estimate the performance of the model, we need to split the dataset into train and test parts. In reality, a test could be millions of customers and a train could be a small playground to estimate the campaign. Our current dataset is not that big, so let's say the test would be just 30% of the dataset. Use `train_test_split` to make a split. Please set the `random_state` argument to 42 and don't forget to shuffle and stratify.\n",
    "How many positive labels do you have in test targets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3. Basic models\n",
    "\n",
    "Let's start with the most basic models. We going to use logistic regression, and classifier, and random forest without any modification or param tuning. This way we could be sure our future modification would indeed make the model stronger.\n",
    "\n",
    "Some of the features are not usable in the current form, e.g. `Dt_Customer` as a date or `Education` as categorical, so let's make a copy of x with the following columns for the section:\n",
    "\n",
    "'Year_Birth', 'Kidhome',\n",
    "'Teenhome',  'Recency', 'MntWines', 'MntFruits',\n",
    "'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts',\n",
    "'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases',\n",
    "'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth', 'Complain'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.1\n",
    "\n",
    "Build a logistic regression model. Set max_iter parameter to 5000. What is the f1_score for the model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.2\n",
    "\n",
    "Build a k-neighbors classifier. What is the f1_score for the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.3\n",
    "\n",
    "Build a random forest classifier. What is the f1_score for the model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.4\n",
    "\n",
    "The models without fine-tuning are not as effective. First, let's try to regularize the regression with the L2 norm. Use 5-split cross-validation grid search to find the optimal C. What is the f1 score for the model trained on the full train dataset with this regularization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.5\n",
    "\n",
    "Fine-tune a k-NN classifier, try to find an optimal number of neighbors, weights, and p with a 5-split cross-validation. What is the f1 score for a model trained on a full train dataset with these parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.6\n",
    "\n",
    "Use the 5-split CV to find the optimal number of estimators and max_features for the random forest. What is the f1 score for random forest trained on a full train dataset with these parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Working with features\n",
    "\n",
    "Machine learning is sometimes called data science because everything depends on data. In this section, we'll apply some of the most popular modifications for data. IMPORTANT: In the previous section we took a subset of the columns; now it's time to work with all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.1\n",
    "\n",
    "One of the standard procedures is data standardizations - it strongly influences the results of k-NN and make the convergence of other algorithms (i.e. logreg and neural nets) much faster. Let's apply `StandardScaler` for all the numerical columns - 'Recency', 'Year_Birth', 'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds', 'NumDealsPurchases', 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', 'NumWebVisitsMonth'. \n",
    "\n",
    "What is the maximum value of MntWines now in the test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.2\n",
    "We have two categorical columns - education and marital status. We can't use them directly with our models, so let's use one-hot encoding - create a separate binary column for each possible value and drop the original 'Education' and 'Marital_Status' columns.\n",
    "\n",
    "How many columns do we have now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.3 \n",
    "We have a datetime column - customer registration date `Dt_Customer`. We can't use it directly, but we could use some derivative features. Let's create new columns 'recent_customer' with value `1` if a user was registered after `01/06/2020` and `0` otherways. The original `Dt_Customer` column should be dropped. How many recent customers do we have in the train set?\n",
    "\n",
    "Hints: you can use `pd.to_datetime` for the column and `datetime.datetime` to create a new date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.4\n",
    "\n",
    "To check the effects of the modification, train the logistic regression with an optimal C. What is the f1 score now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4.5\n",
    "\n",
    "Another popular metric for unbalanced classification tasks is the ROC curve. Train a k-NN and random forest with optimal params and build a roc-curve for both of them on the sample plot. What is the difference between them on FPR 0.7 (approximately)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5.1 (2 points)\n",
    "\n",
    "Propose two derivative features and retrain one of the models with them. What is the performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Q5.2\n",
    "\n",
    "Train an xboost model with f1 score 0.47+"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "kickstarter.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
